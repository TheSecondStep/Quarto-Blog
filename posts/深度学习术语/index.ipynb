{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c828a25",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"深度学习术语表\"\n",
    "author: \"逃之夭夭\"\n",
    "date: \"2026-01-28\"\n",
    "categories: [deep learning]\n",
    "image: \"images/index.jpg\"\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e71fca1",
   "metadata": {},
   "source": [
    "| 术语 | 定义 |\n",
    "| :--- | :--- |\n",
    "| **ReLU** | 线性整流函数。输入为负数时返回 0，输入为正数时保持不变。 |\n",
    "| **小批量 (Mini-batch)** | 将一小组输入数据和标签打包成两个数组。梯度下降的每一步更新都是基于这个“批次”完成的（而不是针对整个数据集）。 |\n",
    "| **前向传播 (Forward pass)** | 将输入数据输入模型并计算出预测结果的过程。 |\n",
    "| **损失 (Loss)** | 一个衡量模型预测效果好坏的数值。 |\n",
    "| **梯度 (Gradient)** | 损失函数相对于模型某个参数的导数。 |\n",
    "| **反向传播 (Backward pass)** | 计算损失函数相对于模型所有参数的梯度的过程。 |\n",
    "| **梯度下降 (Gradient descent)** | 沿着梯度的反方向调整模型参数，从而使模型参数向更优的方向迈进。 |\n",
    "| **学习率 (Learning rate)** | 在使用 SGD 更新模型参数时，决定每一步“迈多大”的比例因子。 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
